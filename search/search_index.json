{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Quick Start Welcome to the Zubhub Dev Docs ! This page will walk you through how to setup your Developer Environment and Run ZubHub on your local machine. Prerequisties WSL OR Linux - VM / Dual boot Github Docker Docker Compose Make Cloning Repo : Clone the Zubhub Repo using the following commands git clone https://github.com/unstructuredstudio/zubhub.git Alternatively on Linux machine you can install docker by running a command given below: bash onetime-setup.sh Make sure you are into the zubhub directory! Change the Directory to the zubhub folder using: cd zubhub Backend: Change directory to ./zubhub_backend Run make init to do all the initial setups required and start the server. make init generates the minimal .env file required to run the backend, spins-up all containers defined in the backend docker-compose file, applies all necessary migrations to the database, and creates a default admin user with username and password of dummy and dummy_password respectively. Subsequently to start and stop the docker containers, use make start , make stop , or make down . (run make help to see all the available make commands). Visit localhost:8000 on your browser to access the API documentation. Frontend: Go inside the Frontend directory by running commands cd .. cd zubhub_frontend/zubhub Create a file named .env in the frontend folder (same directory with package.json) Copy the content of .env.example and paste into the new .env file. cp .env.example .env Run make start to spin up the frontend container. Visit localhost:3000 on your browser to access the frontend.","title":"Installation and Environment Setup"},{"location":"#quick-start","text":"Welcome to the Zubhub Dev Docs ! This page will walk you through how to setup your Developer Environment and Run ZubHub on your local machine.","title":"Quick Start"},{"location":"#prerequisties","text":"WSL OR Linux - VM / Dual boot Github Docker Docker Compose Make","title":"Prerequisties"},{"location":"#cloning-repo","text":"Clone the Zubhub Repo using the following commands git clone https://github.com/unstructuredstudio/zubhub.git Alternatively on Linux machine you can install docker by running a command given below: bash onetime-setup.sh Make sure you are into the zubhub directory! Change the Directory to the zubhub folder using: cd zubhub","title":"Cloning Repo:"},{"location":"#backend","text":"Change directory to ./zubhub_backend Run make init to do all the initial setups required and start the server. make init generates the minimal .env file required to run the backend, spins-up all containers defined in the backend docker-compose file, applies all necessary migrations to the database, and creates a default admin user with username and password of dummy and dummy_password respectively. Subsequently to start and stop the docker containers, use make start , make stop , or make down . (run make help to see all the available make commands). Visit localhost:8000 on your browser to access the API documentation.","title":"Backend:"},{"location":"#frontend","text":"Go inside the Frontend directory by running commands cd .. cd zubhub_frontend/zubhub Create a file named .env in the frontend folder (same directory with package.json) Copy the content of .env.example and paste into the new .env file. cp .env.example .env Run make start to spin up the frontend container. Visit localhost:3000 on your browser to access the frontend.","title":"Frontend:"},{"location":"deploy/","text":"Deploy Fullstack App In One VM. Steps to be followed: create a VM and set up the server. clone the repository from Github. run deploy_unscalable_fullstack.sh set appropriate env variables repeat 2 and 3 Create a VM and set up the server: (you can skip this step if you already have a server running. Note that we assume that your server is Ubuntu 20.04. The auto-installation of docker and docker-compose might not work as expected on a server that is not Ubuntu 20.04) Head over to your cloud provider of choice and create a VM. When done with VM creation, set up your VM (things like firewall, permissions, etc). Note that this deployment should always be done while logged in as root user or else it might fail. Also, ensure that your /home directory is empty, or at least doesn't contain any files or folders named zubhub, zubhub_frontend, or zubhub_backend. Clone the repository from Github still logged in as root, cd into/home and clone the repository cd /home git clone <github repository url> In our case, our repository URL is https://github.com/unstructuredstudio/zubhub","title":"Full Stack Deploy Guide"},{"location":"deploy/#deploy-fullstack-app-in-one-vm","text":"","title":"Deploy Fullstack App In One VM."},{"location":"deploy/#steps-to-be-followed","text":"create a VM and set up the server. clone the repository from Github. run deploy_unscalable_fullstack.sh set appropriate env variables repeat 2 and 3","title":"Steps to be followed:"},{"location":"deploy/#create-a-vm-and-set-up-the-server","text":"(you can skip this step if you already have a server running. Note that we assume that your server is Ubuntu 20.04. The auto-installation of docker and docker-compose might not work as expected on a server that is not Ubuntu 20.04) Head over to your cloud provider of choice and create a VM. When done with VM creation, set up your VM (things like firewall, permissions, etc). Note that this deployment should always be done while logged in as root user or else it might fail. Also, ensure that your /home directory is empty, or at least doesn't contain any files or folders named zubhub, zubhub_frontend, or zubhub_backend.","title":"Create a VM and set up the server:"},{"location":"deploy/#clone-the-repository-from-github","text":"still logged in as root, cd into/home and clone the repository cd /home git clone <github repository url> In our case, our repository URL is https://github.com/unstructuredstudio/zubhub","title":"Clone the repository from Github"},{"location":"media_container/","text":"Media Container On Zubhub, there are two ways to handle media storage. We can use online services to host our media files (We currently only support digital ocean spaces for images and Cloudinary for videos files), or we can opt to host it locally on the media container. This container runs a custom Django code used to handle the upload and serving of images and video. Below is interactive documentation of the media server API endpoints:","title":"Media Container"},{"location":"media_container/#media-container","text":"On Zubhub, there are two ways to handle media storage. We can use online services to host our media files (We currently only support digital ocean spaces for images and Cloudinary for videos files), or we can opt to host it locally on the media container. This container runs a custom Django code used to handle the upload and serving of images and video. Below is interactive documentation of the media server API endpoints:","title":"Media Container"},{"location":"others/","text":"Other Containers Database Container As the name suggests, this is where our SQL database runs. Containers like the web container and the celery container connect to this container to perform useful tasks. The Diagram below is the entity-relationship diagram of every table in our database. RabbitMQ Container This container runs our rabbitMQ message broker. the message broker serves as the link between the web container and the celery container, passing messages/jobs from our web container to the celery container where those jobs are performed. Celery Container This container is used to run background tasks, like delete operations, sending notifications, periodic tasks, anything that should run in the application context Nginx Container This is a custom Nginx container that serves as a reverse proxy for our backend in production. It handles request routing, SSL certificate generation, and auto-renewal. On our Frontend, we run a minimum of one container in development and two in production. Frontend Container Our frontend code lives on this container. When a user first makes a request to our domain, this container is responsible for serving the bundled assets required to run the frontend on their device. Frontend Nginx Container This container runs the same image as the Nginx container on our backend deployment. It serves the same purpose as the backend Nginx container but for the frontend this time. CI/CD Right now, our CI/CD process is based on Github actions and our deployment scripts can be found in the .github folder on the root folder. Generally, as a new contributor, you don't need to worry much about this folder because you generally won't be working on the deployment scripts. The locust folder is where all the stress testing scripts live. This is used to stress-test our production app and profile the performance so we can see in real-time how our system performs under varying load conditions.","title":"Other Containers"},{"location":"others/#other-containers","text":"","title":"Other Containers"},{"location":"others/#database-container","text":"As the name suggests, this is where our SQL database runs. Containers like the web container and the celery container connect to this container to perform useful tasks. The Diagram below is the entity-relationship diagram of every table in our database.","title":"Database Container"},{"location":"others/#rabbitmq-container","text":"This container runs our rabbitMQ message broker. the message broker serves as the link between the web container and the celery container, passing messages/jobs from our web container to the celery container where those jobs are performed.","title":"RabbitMQ Container"},{"location":"others/#celery-container","text":"This container is used to run background tasks, like delete operations, sending notifications, periodic tasks, anything that should run in the application context","title":"Celery Container"},{"location":"others/#nginx-container","text":"This is a custom Nginx container that serves as a reverse proxy for our backend in production. It handles request routing, SSL certificate generation, and auto-renewal. On our Frontend, we run a minimum of one container in development and two in production.","title":"Nginx Container"},{"location":"others/#frontend-container","text":"Our frontend code lives on this container. When a user first makes a request to our domain, this container is responsible for serving the bundled assets required to run the frontend on their device.","title":"Frontend Container"},{"location":"others/#cicd","text":"Right now, our CI/CD process is based on Github actions and our deployment scripts can be found in the .github folder on the root folder. Generally, as a new contributor, you don't need to worry much about this folder because you generally won't be working on the deployment scripts. The locust folder is where all the stress testing scripts live. This is used to stress-test our production app and profile the performance so we can see in real-time how our system performs under varying load conditions.","title":"CI/CD"},{"location":"overview/","text":"Architechture Overview Our Infrastructure is built on docker and docker-compose and that makes it easy for us to manage the various issues that arise when development and deployment environments are different. The backend consists of various components called services that need to work together to achieve the desired goal (database service, celery service, rabbitMQ service, media service, etc). Each service lives in its docker container and communicates with the other services through the inbuilt network provided by docker. During deployment, we have two different server configurations, and the choice of which one to use depends on how we want the deployment to scale (horizontal or vertical). The diagram below is a bird' eye view of the configuration of the backend services on your local machine during development. (Note that the frontend container is missing from the diagram below. This diagram will be updated to represent that) If the services are running in vertical scaling configuration in production, the diagram below is how the services communicate and talk with each other and the external world. However if the services are running in the horizontal scaling configuration in production, the diagram below is how the services communicate and talk with each other and the external world. On our backend, we run a minimum of Five containers in development and six containers in production. These containers are the bare minimum and if any is down, the backend either won't function as expected or won't function at all. Web Container Media Container Database Container RabbitMQ Container Celery Container","title":"Architechture Overview"},{"location":"overview/#architechture-overview","text":"Our Infrastructure is built on docker and docker-compose and that makes it easy for us to manage the various issues that arise when development and deployment environments are different. The backend consists of various components called services that need to work together to achieve the desired goal (database service, celery service, rabbitMQ service, media service, etc). Each service lives in its docker container and communicates with the other services through the inbuilt network provided by docker. During deployment, we have two different server configurations, and the choice of which one to use depends on how we want the deployment to scale (horizontal or vertical). The diagram below is a bird' eye view of the configuration of the backend services on your local machine during development. (Note that the frontend container is missing from the diagram below. This diagram will be updated to represent that) If the services are running in vertical scaling configuration in production, the diagram below is how the services communicate and talk with each other and the external world. However if the services are running in the horizontal scaling configuration in production, the diagram below is how the services communicate and talk with each other and the external world. On our backend, we run a minimum of Five containers in development and six containers in production. These containers are the bare minimum and if any is down, the backend either won't function as expected or won't function at all. Web Container Media Container Database Container RabbitMQ Container Celery Container","title":"Architechture Overview"},{"location":"web_container/","text":"Web Container The web container hosts our backend code. Most API requests end up in this container. Below Is interactive documentation of the webserver API Endpoints:","title":"Web Container"},{"location":"web_container/#web-container","text":"The web container hosts our backend code. Most API requests end up in this container. Below Is interactive documentation of the webserver API Endpoints:","title":"Web Container"}]}